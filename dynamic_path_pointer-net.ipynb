{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Dynamic_Path_PointerNet_TSP_FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuf21gqhRgYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from itertools import permutations\n",
        "\n",
        "\n",
        "class PointMaker:\n",
        "    def __init__(self):\n",
        "        self.points = []\n",
        "        self.graph = []\n",
        "\n",
        "    def path_solve(self, d):           #solve tsp dynamically given an adjacency matrix\n",
        "\n",
        "        def memoize(f):                #memoize to generate path-cost dictionary\n",
        "            memo_dict = {}\n",
        "\n",
        "            def memo_func(*args):     \n",
        "                if args not in memo_dict:\n",
        "                    memo_dict[args] = f(*args)\n",
        "                return memo_dict[args]\n",
        "\n",
        "            memo_func.clear = lambda: memo_dict.clear()\n",
        "            return memo_func\n",
        "\n",
        "        @memoize\n",
        "        def rec_path_solve(c, ts):            #Go through the TSP dynamically\n",
        "            assert c not in ts\n",
        "            if ts:\n",
        "                vals = []\n",
        "                for lc in ts:\n",
        "                    aval = d[lc][c] + rec_path_solve(lc, ts - set([lc]))[0] #Recursion over the possible inputs \n",
        "                    vals.append((aval, lc))\n",
        "                if (vals == []):\n",
        "                    return (999, lc)\n",
        "                val = min(vals)\n",
        "                return val\n",
        "            else:\n",
        "                return (d[0][c], 0)\n",
        "\n",
        "        best_tour = []\n",
        "        c = 0\n",
        "        cs = frozenset(range(1, len(d)))        #Generate frozen set for possible inputs from the graph\n",
        "        while True:\n",
        "            l, lc = rec_path_solve(c, cs)\n",
        "            if lc == 0:\n",
        "                break\n",
        "            best_tour.append(lc)\n",
        "            c = lc\n",
        "            cs = cs - frozenset([lc])\n",
        "\n",
        "        best_tour = tuple(reversed(best_tour))\n",
        "\n",
        "        return best_tour\n",
        "\n",
        "    def get_paths(self, d, s, t):                   #Get optimum path cost from point s to t\n",
        "        opts = list(range(len(d)))\n",
        "        perms = set(permutations(opts))\n",
        "        minval = 999\n",
        "        min_path = []\n",
        "        flag = 1\n",
        "        for perm in perms:\n",
        "            sum_tour = 0\n",
        "\n",
        "            for i in range(len(perm) - 1):\n",
        "                sum_tour += d[perm[i]][perm[i + 1]]\n",
        "                if (sum_tour > minval):\n",
        "                    flag = 0\n",
        "                    break\n",
        "            if (flag):\n",
        "                sum_tour +=d[perm[-1]][t]\n",
        "                sum_tour += d[0][perm[s]]\n",
        "\n",
        "                if (sum_tour < minval):\n",
        "                    min_path = list(perm)\n",
        "                    minval = sum_tour\n",
        "            else:\n",
        "                continue\n",
        "        return min_path  # , minval    #Return the optimum path\n",
        "\n",
        "    def get_distance(self, point1, point2):       #Get the Eucledian distance from two coordinates\n",
        "        sums = 0\n",
        "        for x in range(len(point1)):\n",
        "            sums += ((point1[x] - point2[x]) ** 2)\n",
        "        distance = np.sqrt(sums)\n",
        "        return distance\n",
        "\n",
        "    def calculate_graph(self, points): #calculate the adjacency matrix given the points\n",
        "        adj_matrix = []\n",
        "        for i, point1 in enumerate(points):\n",
        "            row = []\n",
        "            for j, point2 in enumerate(points):\n",
        "                distance = self.get_distance(point1, point2)\n",
        "                row.append(distance)\n",
        "            adj_matrix.append(row)\n",
        "        return np.array(adj_matrix)\n",
        "\n",
        "\n",
        "    def generate_points(self, batch_size, number, size): #generate points and calculate paths from those points\n",
        "        batches = []\n",
        "        graphs = []\n",
        "        paths = []\n",
        "        for _ in range(batch_size):\n",
        "            points = np.random.rand(number, size)        # Generate random points \n",
        "            batches.append(np.array(points))          \n",
        "            graph = self.calculate_graph(points)         # calculate the adjacency matrices\n",
        "            graphs.append(graph)\n",
        "            path = list(self.get_paths(graph, 0, number-1)) #get the optimump aths from initial points to end points of the graph\n",
        "            paths.append(path)\n",
        "        return batches, paths\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S6htI_KN9EE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aurelienbibaut/Actor_CriticPointer_Network-TSP.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADaPDoaNQkM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd Actor_CriticPointer_Network-TSP/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H97wmjZN2lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tsp_env\n",
        "hidden_size = 128\n",
        "embedding_size = 128\n",
        "max_time_steps = 5; input_size = 2;\n",
        "batch_size = 256\n",
        "initialization_stddev = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP6TQYe7EJEv",
        "colab_type": "text"
      },
      "source": [
        "tf.placeholder - allocates memory of tensor for later use\n",
        "\n",
        "W_embed - initializes the weights of the size of inputs with normal randomization\n",
        "\n",
        "einsum does a matrix multiplication to embed the inputs like this:\n",
        "\n",
        "$einsum('ij,jk->ik', m0, m1)$    #output[i,k] = $sum_j m0[i,j] * m1[j, k]$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "z4lUl-byN2le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_inputs = tf.placeholder(tf.float32, [batch_size, max_time_steps, input_size])\n",
        "W_embed = tf.Variable(tf.random_normal([embedding_size, input_size],\n",
        "                                       stddev=initialization_stddev))\n",
        "embedded_inputs = tf.einsum('kl,itl->itk', W_embed, enc_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbFzIz5pKm2F",
        "colab_type": "text"
      },
      "source": [
        "#Encoding \n",
        "The Encoder takes the input sequence and maps it into a higher dimensional space (n-dimensional vector). That abstract vector is fed into the Decoder which turns it into an output sequence. The output sequence can be in another language, symbols, a copy of the input, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5XA4qWoBN2lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.variable_scope(\"encoder\"):\n",
        "    enc_rnn_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
        "    enc_outputs, enc_final_state = tf.nn.dynamic_rnn(cell=enc_rnn_cell, \n",
        "                                                     inputs=embedded_inputs,\n",
        "                                                     dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx7xuryjLAGz",
        "colab_type": "text"
      },
      "source": [
        "#Attention\n",
        "\n",
        "Attention for Pointer networks is uses so the decoder can look back and forwards in the input. Therefore, it has access to encoder states from each step, not just the last one.\n",
        "\n",
        "The mask is a preset distribution of weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d01uoKbZN2lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention_mask(W_ref, W_q, v, enc_outputs, query, already_played_actions=None, \n",
        "                   already_played_penalty=1e6):\n",
        "    with tf.variable_scope(\"attention_mask\"):\n",
        "        u_i0s = tf.einsum('kl,itl->itk', W_ref, enc_outputs)\n",
        "        u_i1s = tf.expand_dims(tf.einsum('kl,il->ik', W_q, query), 1)\n",
        "        u_is = tf.einsum('k,itk->it', v, tf.tanh(u_i0s + u_i1s)) - already_played_penalty * already_played_actions\n",
        "        return u_is, tf.nn.softmax(u_is)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUC4-bTcM59j",
        "colab_type": "text"
      },
      "source": [
        "#Decoding and Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaQFUKRhN2ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.variable_scope(\"decoder\"):\n",
        "    decoder_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)  #set an LSTM as decoding cell\n",
        "    decoder_state = [enc_final_state]\n",
        "    first_decoder_input = tf.tile(tf.Variable(tf.random_normal([1, embedding_size]), #get input from Latent space\n",
        "                                      name='first_decoder_input'), [batch_size, 1])\n",
        "    \n",
        "    decoder_targets = tf.placeholder(dtype=tf.int32, shape=[batch_size, max_time_steps])  #get the training labels to compare LSTM outputs\n",
        "    \n",
        "    with tf.variable_scope(\"attention_weights\", reuse=True):\n",
        "        W_ref = tf.Variable(tf.random_normal([embedding_size, embedding_size], \n",
        "                                             stddev=initialization_stddev),\n",
        "                           name='W_ref')\n",
        "        W_q = tf.Variable(tf.random_normal([embedding_size, embedding_size],    \n",
        "                                           stddev=initialization_stddev),\n",
        "                         name='W_q')\n",
        "        v = tf.Variable(tf.random_normal([embedding_size], stddev=initialization_stddev),\n",
        "                        name='v')\n",
        "    \n",
        "    # Training chain\n",
        "    loss = 0\n",
        "    decoder_input = first_decoder_input\n",
        "    decoder_state = enc_final_state\n",
        "    already_played_actions = tf.zeros(shape=[batch_size, max_time_steps], dtype=tf.float32) # initialize states\n",
        "    decoder_inputs = [decoder_input]\n",
        "    for t in range(max_time_steps):\n",
        "        dec_cell_output, decoder_state = decoder_cell(inputs=decoder_input, \n",
        "                                          state=decoder_state)\n",
        "        attn_logits, _ = attention_mask(W_ref, W_q, v, enc_outputs, dec_cell_output,\n",
        "                                        already_played_actions=already_played_actions,\n",
        "                                        already_played_penalty=1e6)\n",
        "        loss += tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(decoder_targets[:, t],\n",
        "                                                                          depth=max_time_steps),\n",
        "                                                        logits=attn_logits))\n",
        "        loss_summary_sy = tf.summary.scalar('training_loss', loss)\n",
        "\n",
        "        # Teacher forcing of the next input\n",
        "        decoder_input = tf.einsum('itk,it->ik', embedded_inputs,\n",
        "                                  tf.one_hot(decoder_targets[:, t], depth=max_time_steps))\n",
        "        decoder_inputs.append(decoder_input)\n",
        "        already_played_actions += tf.one_hot(decoder_targets[:, t], depth=max_time_steps)\n",
        "    \n",
        "    # Inference chain\n",
        "    decoder_input = first_decoder_input\n",
        "    decoder_state = enc_final_state\n",
        "    decoder_outputs = []\n",
        "    already_played_actions = tf.zeros(shape=[batch_size, max_time_steps], dtype=tf.float32)\n",
        "    for t in range(max_time_steps):\n",
        "        dec_cell_output, decoder_state = decoder_cell(inputs=decoder_input,\n",
        "                                                      state=decoder_state)\n",
        "        _, attn_mask = attention_mask(W_ref, W_q, v, enc_outputs, dec_cell_output,\n",
        "                                      already_played_actions=already_played_actions,\n",
        "                                      already_played_penalty=1e6)\n",
        "        decoder_outputs.append(tf.argmax(attn_mask, axis=1))\n",
        "        decoder_input = tf.einsum('itk,it->ik', embedded_inputs, attn_mask)\n",
        "        already_played_actions += tf.one_hot(decoder_outputs[-1], depth=max_time_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0lHY3V0N2ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(1e-2) #use Adam optimizer with a learning rage of 0,001\n",
        "train_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4eb9KtN2ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()\n",
        "log_files_name = 'PointerNet-TSP5'\n",
        "writer = tf.summary.FileWriter('/tmp/' + log_files_name, sess.graph) #Generate network summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "HaUsGnFUN2lu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "727a62a0-ab65-4ef5-f89d-7a5293b9b652"
      },
      "source": [
        "batch_size = 256\n",
        "n_cities = 5\n",
        "loss_vals = []\n",
        "mean_approx_ratios = []\n",
        "amax = 0\n",
        "\n",
        "\n",
        "# Train the network over 4000 epochs\n",
        "for i in range(4000):\n",
        "    inputs_batch, labels_batch = pts.generate_points(batch_size,n_cities,2)\n",
        "    #print(labels_batch)\n",
        "    loss_summary, loss_val, _ = sess.run([loss_summary_sy, loss, train_op], \n",
        "                                         feed_dict={enc_inputs: inputs_batch, \n",
        "                                                        decoder_targets: labels_batch})\n",
        "    loss_vals.append(loss_val)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Add training loss to tensorboard logs\n",
        "    if i % 1000 == 0:\n",
        "        writer.add_summary(loss_summary, i)\n",
        "        writer.flush()\n",
        "        print(\"Loss:\",loss_vals[-1])\n",
        "        \n",
        "    # Test accuracy\n",
        "    if i % 1000 == 0:\n",
        "        envs = []\n",
        "        inputs_list = []\n",
        "        optimal_rewards = []\n",
        "        optimal_tours = []\n",
        "        # Generate and initialize a batch of environments\n",
        "        inputs_batch, labels_batch = pts.generate_points(batch_size,n_cities,2)\n",
        "          \n",
        "        inputs_batch = np.array(inputs_batch)\n",
        "        # Use the PointerNet on this test batch and get its predictions\n",
        "        \n",
        "        predicted_outputs = np.array(sess.run(decoder_outputs, \n",
        "                                              feed_dict={enc_inputs: inputs_batch})).T\n",
        "        counts = 0\n",
        "        tots = 0\n",
        "        \n",
        "        for i in range(10):\n",
        "          print(\"P:\",predicted_outputs[i], \" R:\", labels_batch[i],end=' ')\n",
        "          if(np.all(predicted_outputs[i]==labels_batch[i])):\n",
        "            print(\"Y\")\n",
        "          else:\n",
        "            print(\"N\")\n",
        "        for i in range(batch_size):\n",
        "          if(np.all(predicted_outputs[i]==labels_batch[i])):\n",
        "            counts +=1\n",
        "          tots +=1\n",
        "        print(counts,tots,counts/tots, amax)\n",
        "        if(counts/tots > amax):\n",
        "          saver = tf.train.Saver()\n",
        "          saver.save(sess, 'path_final_model9sm.model')\n",
        "          amax= counts/tots\n",
        "          print(\"saved\",counts/tots)\n",
        "        \n",
        "\n",
        "# Plot the training losses\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(loss_vals)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f25f767b320>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXlvjFGWNlLL",
        "colab_type": "text"
      },
      "source": [
        "Loss over epoch plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcy6L6JxIblQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boe0bHFPE4nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DynamicTSP():\n",
        "  def __init__(self):\n",
        "    self.points = points\n",
        "    self.min_cost = 999\n",
        "\n",
        "  def path_cost(self,path,graph):\n",
        "    cost = 0\n",
        "    for i in range(len(path)-1):\n",
        "        cost+=graph[path[i]][path[i+1]]\n",
        "    return cost\n",
        "\n",
        "  def predict_cost(self,inputs_batch,graph):\n",
        "    inputs_batch = [inputs_batch]*128\n",
        "    inputs_batch = np.array(inputs_batch)\n",
        "    predicted_outputs = np.array(sess.run(decoder_outputs, feed_dict={enc_inputs: inputs_batch})).T[0]\n",
        "    cost = self.path_cost(predicted_outputs,graph)\n",
        "    return cost\n",
        "\n",
        "  def tsp_dp_solve(self,d): #Dynamic TSP solver\n",
        "      def memoize(f):\n",
        "          memo_dict = {}\n",
        "          def memo_func(*args):\n",
        "              if args not in memo_dict:\n",
        "                  memo_dict[args] = f(*args)\n",
        "              return memo_dict[args]\n",
        "          memo_func.clear = lambda: memo_dict.clear()\n",
        "          return memo_func\n",
        "\n",
        "      @memoize\n",
        "      def rec_tsp_solve(c, ts):\n",
        "          if ts:\n",
        "            vals = []\n",
        "            for lc in ts:\n",
        "              vals.append((d[lc][c] + rec_tsp_solve(lc, ts - set([lc]))[0], lc))\n",
        "            val = min(vals)\n",
        "            return val\n",
        "          else:\n",
        "            return (d[0][c], 0)\n",
        "\n",
        "      best_tour = []\n",
        "      c = 0\n",
        "      cs = frozenset(range(1, len(d)))\n",
        "      while True:\n",
        "          l, lc = rec_tsp_solve(c, cs)\n",
        "          if lc == 0:\n",
        "              break\n",
        "          best_tour.append(lc)\n",
        "          c = lc\n",
        "          cs = cs - frozenset([lc])\n",
        "\n",
        "      best_tour = tuple(reversed(best_tour))\n",
        "\n",
        "      return best_tour\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkWwqNkkq6EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DynamicTSP2():\n",
        "  def __init__(self,points,graph):\n",
        "    self.points = points\n",
        "    self.pred_cities = 5\n",
        "    self.min_cost = 999\n",
        "    self.cts = 0\n",
        "    self.tots = 0\n",
        "\n",
        "  def path_cost(self,path,graph):\n",
        "    cost = 0\n",
        "    for i in range(len(path)-1):\n",
        "        cost+=graph[path[i]][path[i+1]]\n",
        "    return cost\n",
        "\n",
        "  def predict_cost(self,current,points,index,graph): # Predict the cost of the points\n",
        "    inputs_batch = points[index]\n",
        "    inputs_batch = [inputs_batch]*256\n",
        "    inputs_batch = np.array(inputs_batch)\n",
        "    #Generate prediction over 0 to n_cities\n",
        "    predicted_outputs = np.array(sess.run(decoder_outputs, feed_dict={enc_inputs: inputs_batch})).T[0]\n",
        "    pred_outs = []\n",
        "    #reindex the path\n",
        "    for x in predicted_outputs:\n",
        "      pred_outs.append(index[x])\n",
        "    #Get cost by joining the path\n",
        "    cost = self.path_cost(pred_outs,graph)+graph[current][pred_outs[0]]+graph[current][pred_outs[-1]]\n",
        "    return cost\n",
        "\n",
        "  def tsp_dp_solve2(self,d):\n",
        "        def memoize(f):             #memoize: generate path to cost map\n",
        "            memo_dict = {}\n",
        "            def memo_func(*args):\n",
        "                if args not in memo_dict:\n",
        "                    memo_dict[args] = f(*args)\n",
        "                return memo_dict[args]\n",
        "            memo_func.clear = lambda: memo_dict.clear()\n",
        "            return memo_func\n",
        "\n",
        "        @memoize\n",
        "        def rec_path_solve(c, ts):\n",
        "            assert c not in ts\n",
        "            if ts:\n",
        "                if (len(ts) == n_cities):\n",
        "                    points = np.array(self.points)\n",
        "                    indx = list(ts)\n",
        "                    cost = self.predict_cost(c,points,indx, graph) #Generate cost prediction\n",
        "                    first = list(ts)[0]\n",
        "                    if (self.min_cost >cost+d[first][c]):\n",
        "                      self.min_cost = cost+d[first][c]\n",
        "                vals = []\n",
        "                for lc in ts:\n",
        "                    aval = d[lc][c] + rec_path_solve(lc, ts - set([lc]))[0]\n",
        "                    self.tots +=1\n",
        "                    if (aval < self.min_cost):        #Bound the check cost\n",
        "                        self.cts+=1\n",
        "                        vals.append((aval, lc))\n",
        "                    \n",
        "                if (vals == []):\n",
        "                    return (999, lc)\n",
        "                val = min(vals)\n",
        "                return val\n",
        "            else:\n",
        "                return (d[0][c], 0)\n",
        "\n",
        "        best_tour = []\n",
        "        c = 0\n",
        "        cs = frozenset(range(1, len(d))) #Set the possible points\n",
        "        while True:\n",
        "            l, lc = rec_path_solve(c, cs)\n",
        "            if lc == 0:\n",
        "                break\n",
        "            best_tour.append(lc)\n",
        "            c = lc\n",
        "            cs = cs - frozenset([lc])\n",
        "        best_tour = tuple(reversed(best_tour))\n",
        "\n",
        "        return best_tour"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgJT279_R4mP",
        "colab_type": "code",
        "outputId": "cf23866a-e6da-482b-8adc-b70cfd0bb2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import time \n",
        "t0 = time.time()\n",
        "datas = pts.generate_points(1,10,2)      #Generate points\n",
        "points = datas[0][0]\n",
        "graph = pts.calculate_graph(points)      #Calculate graphs\n",
        "print(datas)\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "dtsp = DynamicTSP()                      #Test dynamic programming 1\n",
        "out_real = dtsp.tsp_dp_solve(graph)       \n",
        "print(out_real, dtsp.path_cost(out_real,graph))\n",
        "t2  = time.time()\n",
        "print(\"Dynamic algorithm time\",t2-t1) \n",
        "dtsp2 = DynamicTSP2(points,graph)        #Test dynamic programming 2\n",
        "out_pred = dtsp2.tsp_dp_solve2(graph)    \n",
        "print(out_pred,dtsp.path_cost(out_real,graph))\n",
        "t3 = time.time()\n",
        "print(\"Dynamic algorithm with neural network time\",t3-t2)\n",
        "print()\n",
        "print(\"Number of operations with predicted bound vs Number of operations without bound:\")\n",
        "print(\"                                  \",dtsp2.cts, \"      \",dtsp2.tots)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([array([[0.95659873, 0.15649118],\n",
            "       [0.73822391, 0.13313602],\n",
            "       [0.15325601, 0.35116317],\n",
            "       [0.60251944, 0.58686999],\n",
            "       [0.28976751, 0.80131566],\n",
            "       [0.06024383, 0.92342092],\n",
            "       [0.62939841, 0.38233842],\n",
            "       [0.66459971, 0.20725036],\n",
            "       [0.68337566, 0.12588178],\n",
            "       [0.15161645, 0.45579887]])], [[6, 3, 4, 5, 9, 2, 7, 8, 1]])\n",
            "(6, 3, 4, 5, 9, 2, 7, 8, 1) 2.096639125235892\n",
            "Dynamic algorithm time 0.018828630447387695\n",
            "(1, 2, 3, 4, 5, 6, 7, 8, 9) 2.096639125235892\n",
            "Dynamic algorithm with neural network time 8.760294675827026\n",
            "\n",
            "Number of operations with predicted bound vs Number of operations without bound:\n",
            "                                   2583        9225\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}